---
title: "Customer matching using random forest"
author: Stefan
date: 2019-01-31
slug: random_forest_matching
categories:
  - R
tags:
  - matching
  - random_forest
  - ranger
  - proximity_matrix
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(stringr)
library(lubridate)
library(dplyr)

date_sequence <- function(firstCohort, lastCohort) {
  
  firstCohort <- ymd(firstCohort)
  lastCohort <- ymd(lastCohort)
  
  cohortMonths <- as.character(seq(firstCohort, lastCohort, by = "month"))
}

outputFolder <- "/t-drive/Clients/Woolworths/2014-05-28_Vitality_uplift/2017-06/"

demographicsFiles <- list.files(str_c(outputFolder, "Output/Customer_data/"), pattern = "customer_data_")

spendFilesNonIdentified <- list.files(str_c(outputFolder, "Output/Spend_data/"), pattern = "spend_data_non_identified")

batchNameVecNonIdentified <- c("Non_alien_loyal", "Non_alien_total")

cohortMonths <- date_sequence("2013-03-01", "2017-12-31")

  demographicsFile <- demographicsFiles[10]
  spendFile <- spendFilesNonIdentified[10]
  # listOfCustomerNumberBatchesNonIdentified[]
  # customerNumbersForBatch <- listOfCustomerNumberBatchesNonIdentified[[j]]
  batchName <- batchNameVecNonIdentified[1]
  cohortMonth <- cohortMonths[11]

rf_data <- 
readRDS(str_c(outputFolder, "Output/Batch_data/", batchName, "/MFA/MFA_", batchName, "_", 
                                str_replace_all(cohortMonth, '-', '_'), ".rds")) %>% 
  mutate(customer_no = customer_no %>% as.character %>% openssl::md5() )

MFAData <- 
  readRDS(str_c(outputFolder, "Output/Batch_data/", batchName, "/MFA/MFA_", batchName, "_", 
                                str_replace_all(cohortMonth, '-', '_'), ".rds")) %>% 
  mutate(customer_no = customer_no %>% as.character %>% openssl::md5() )

```

## Introduction

Measuring treatment effect in data contexts where the response was already measured without an experimental design usually requires matching to control for confounding effects.

Here I outline matching using random forests to improve on performance over genetic matching while maintaining reasonable matching quality

## Why?

In most cases the first line of attack would be matching using propensity scoring. This is easily done using a GLM logit model with a package like `MatchIt` in R.  

Because this matches on a 1D metric only people often turn to genetic matching for its great quality of matching. This is slow however and production code can end up operating at too high a cost.

## How?

Random forest matching is similar to genetic algorithms because people that are matched together generally have similar traits over many different variables.

The way it manages this is by training a propensity model by growing decision trees. After the forest has been trained we can look at the terminal leaves in all of the trees and see how often the samples ended up in the same predictive nodes. Each node uses different variables. The average of these coocurrence matrices is the proximity matrix used for matching.

## Comparing run times - Random Forests VS Genetic matching

## Implementation of random forest matching

There are many different ways to perform matching using proximity matrices. Using the base `randomForest` package you can specify hyper parameters for the model to keep it's proximity matrices.  

For this blog I decided to define this process using the `ranger` package instead. The main reason is that the `ranger` package is better optimized for big data and multi core processing.

### Packages

To run this code you will need the following packages:

```{r}
# install.packages("ranger")
library(ranger)

# install.packages("ROSE")
library(ROSE)

# install.packages("devtools")
# devtools::install_github("sipemu/similarity")
library(Similarity)

library(dplyr)
```

### Thin feature space

For this specific example our data contains 35 principal components generated by a combination of PCA and MCA models. We will fit our model on the top 5 components:

```{r}
rf_data <-
  rf_data %>% 
  select(1:10) %>% 
  mutate(vitality = vitality %>% factor)

rf_data <- 
  rf_data %>%
  setNames( c("customer_no","vitality","spend_month_2013_10_01","spend_month_2013_11_01","spend_month_2013_12_01","Dim_1","Dim_2", "Dim_3", "Dim_4", "Dim_5" )) 

rf_data %>% glimpse
```


### Fit random forest model

In this example I used the ROSE sampling strategy to achieve class balance because the conversion response was heavily under represented.  

This class imbalance will skew your GLM or random forest model outcome because the entropy or loss function won't be easily optimized to predict the conversion cases; the false positives from all the counter factual responses wouldn't make sense and the model will never try to guess a conversion.  

Don't simply copy paste this methodology! ROSE creates synthetic samples! Understand what you are matching and how you are sampling!

Okay here we go:

```{r}
rf_data <- ROSE(vitality~., data = rf_data %>% select(-customer_no), seed = 8020)$data 
rf_model <- ranger(formula = vitality~. ,data = rf_data,write.forest = T,classification = T)
```

### Calculate proximity matrices

In this case I matches one-to-one. This is important; sometimes it makes more sense to match one-to-many for example.  

Make sure that you record the weights of your matches so that you can weight your aggregations of the response you are trying to compare between these two groups - that is beyond the scope of this blog.  

I take the first 1000 elements to speed up the runtime  

```{r}
treatment_data <- rf_data %>% filter(vitality == 1) %>% .[1:1000,]
control_data <- rf_data %>% filter(vitality == 0) %>% .[1:1000,]

prox_matrix <- 
    Similarity::proximityMatrixRanger(x = treatment_data %>% select(-vitality),y = control_data %>% select(-vitality),rf = rf_model)

```

Here each row will represent a treatment response while each column will represent a controll response.

A 1 row example:  

```{r}

prox_matrix[816,]

# as.matrix(prox_matrix) > 0
# (as.matrix(prox_matrix) > 0) %>% as.vector() %>% which(.)
```


The values in this matrix represent the proximity score of the {x,y} pair.  

In the simple one-to-one case the argmax of each row represents the row_id match for each treatment response ID

### Get matches

Getting the matches is simple since you can just grab the ID's for each response:

```{r}

match_id <- prox_matrix %>% apply(MARGIN = 1,FUN = which.max)

matches_out <- 
  tibble(
    customer_no =   MFAData %>% 
      mutate(vitality = factor(vitality)) %>% 
      filter(vitality==1) %>% 
      pull(customer_no) %>% .[1:1000], 
    match = MFAData %>% 
      mutate(vitality = factor(vitality)) %>% 
      filter(vitality==0) %>% 
      pull(customer_no) %>% .[1:1000] %>% .[match_id],
      weights = 1
    )

matches_out
```

Here I just created a tibble where each customer ID has a corresponding match customer ID.  

Special care must be taken however; if a row has only zero values it is important to handle this edge case. A conscious decision must be made to assign at random or to discard etc.

I assign all of them a weight of 1 since we matched one-to-one; make sure to assign the appropriate weight should you match one-to-many for example (read documentation of the `Similarity::proximityMatrixRanger` function)  

