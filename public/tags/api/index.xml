<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Api on </title>
    <link>/tags/api/</link>
    <description>Recent content in Api on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 27 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/api/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Finding geographical points of interest using Python</title>
      <link>/posts/finding_geographical_points_of_interest_using_python/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/finding_geographical_points_of_interest_using_python/</guid>
      <description>This blog will take a look at scraping the TomTom and Google Places APIs to get all the points of interest in an area. A recursive grid search algorithm is discussed that efficiently identifies all of the POIs in a large area where there is a limit on the number of results the API returns. 
TomTom vs Google First, let&amp;rsquo;s compare each API:
    TomTom Google Places     Max free daily requests 2500 2500   Max results returned 100 20   Point search Yes Yes   Max point search radius none 50km   Rectangle search Yes No   Up-to-date No Yes    In each case, you need to register for your own API key which you include as a parameter in the search.</description>
    </item>
    
    <item>
      <title>Serving a machine learning model via API</title>
      <link>/posts/testing_apis_in_r/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/testing_apis_in_r/</guid>
      <description>About the Plumer package In oder to serve our API we will make use of the great Plumer package in R
 To read more about this package go to:
https://www.rplumber.io/docs/
 Setup Load in some packages.
If you are going to host the api on a suse or redhat linux server make sure you have all the dependencies as well as the packages installed to follow through this example yourself.</description>
    </item>
    
    <item>
      <title>Dealing with nested data</title>
      <link>/posts/using_e-sports_api/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/using_e-sports_api/</guid>
      <description>Dealing with nested data can be really frustrating…
Especially if you want to keep your workspace nice and tidy with all your data in tables!
With no actual experience trying to get at these nested tibbles can seem almost impossible:
via GIPHY
--  Downloading data from an api created by Blizzard To illustrate how you would deal with nested data I found an api that let’s you download all kinds of data on the e-sport/game called Overwatch.</description>
    </item>
    
  </channel>
</rss>