<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Regression on </title>
    <link>/tags/regression/</link>
    <description>Recent content in Regression on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 13 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Condensed R For Data Science: Data Visualisation</title>
      <link>/posts/data-visualisation/</link>
      <pubDate>Fri, 13 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/data-visualisation/</guid>
      <description>Data Visualisation ChapterAesthetic mapping ExercisesFacetsGeomsGeom ExercisesStatistical TransformationsTransformation ExercisesPosition Adjustmentsposition = identityposition = fillposition = dodgeSomething interesting: position = jitterPosition Adjustment exercisesCoordinate SystemsCoord_flip()Coord_quickmap()Coord_polar()Coordinate Systems ExercisesLayered Grammar of GraphicsThis piece is part of a series that serves as a condensed help guide that I use to explore R and the tidyverse packages as I work through R for Data Science available here</description>
    </item>
    
    <item>
      <title>Predict house prices - deep learning, keras</title>
      <link>/posts/predict_house_prices_dnn/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/predict_house_prices_dnn/</guid>
      <description>OverviewNaive model (no time index)Load the dataScale the variablesDefine the modelMeasuring over-fit using k-folds crossvalidationGet resultsBenchmark vs Gradient boosting machinesTime series models using LSTM together with an inference networkRead in the dataRead in the dataProcess dataDesign inference modelDesign LSTM modelTest a LSTM modelEverything setâ€¦ time to get started!Back test LSTM modelCombine LSTM and Inference networks into 1 deep neural network?</description>
    </item>
    
    <item>
      <title>Benchmarking machine learning models in parallel</title>
      <link>/posts/benchmarking_in_parallel/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/benchmarking_in_parallel/</guid>
      <description>OverviewHaving just started playing with deeplearning models in R, I wanted to visually compare them to other more traditional ML workflows. Of course, deeplearning is generally used where other models fail, but with no need for feature selection and rapidly increasing power and ease of use they may just evolve into a general learning paradigm.
However, with tabular data and packages like caret the machine learning methods have become so streamlined that minimal user input is required at all.</description>
    </item>
    
    <item>
      <title>A Soft Introduction to Machine Learning</title>
      <link>/posts/intro-machine-learning/</link>
      <pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/intro-machine-learning/</guid>
      <description>Important machine learning librariesFuture additionsPart 1 - Data PreprocessingPart 2 - RegressionSimple Linear RegressionMultiple linear regressionPolynomial RegressionSupport vector machine regressionRegression TreesRandom forest regressionA more robust application of machine learning regressions (random forest)Part 3 - ClusteringK-meansPart 4 - Dimensionality ReductionCreate PCAPart 5 - Reinforced LearningMulti-Armed Bandit ProblemUpper Confidence Bound (UCB) methodImprove results using UCBVisualize the model add selectionPart 6 - Parameter Grid Search, Cross-validation and BoostingGrid Search and Parameter TuningXGBoostImportant machine learning librariesI created this document to serve as an easy introduction to basic machine learning methods.</description>
    </item>
    
  </channel>
</rss>