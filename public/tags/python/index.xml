<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on </title>
    <link>/tags/python/</link>
    <description>Recent content in Python on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 28 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Setting up a Web App Dev Environment under Windows</title>
      <link>/posts/windows_dev_environment/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/windows_dev_environment/</guid>
      <description>Writing code is hard enough. But it sucks when your desktop OS seems to be actively fighting against you actually getting anything done. The best case scenario is that you&amp;rsquo;re running a Unix/Linux based OS. If you&amp;rsquo;re running something fairly mainstream like Ubuntu, chances are most everything you need works out the box (apart from wireless and graphics card drivers of course) and most of the documentation, tutorials and resources on the internet assume that.</description>
    </item>
    
    <item>
      <title>Predicting cloud movements</title>
      <link>/posts/predicting_cloud_movements/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/predicting_cloud_movements/</guid>
      <description>In this notebook we will attempt to predict or forecast the movement of rain/clouds over the area of North America!
Of course the weather is a known chaotic system, therefore we will try to create an initial benchmark by throwing a deep learning model at the problem.
The images can be downloaded from AWS S3 using the following link https://s3-eu-west-1.amazonaws.com/data-problems/precipitation_data.zip
Import some libraries import os from os import listdir from PIL import Image as PImage import matplotlib.</description>
    </item>
    
    <item>
      <title>Test multiple sklearn models with LIME</title>
      <link>/posts/test_multiple_sklearn_models_blog/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/test_multiple_sklearn_models_blog/</guid>
      <description>In this blog I load the toy dataset for detecting breast cancer. Often before you can fine tune and productionize any model you will have to play with and test a wide range of models.
Luckily we have frameworks like scikit_learn and caret to train many different models! Prepare yourself
import numpy import pandas import matplotlib.pyplot as plt from sklearn import model_selection from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.</description>
    </item>
    
    <item>
      <title>Finding geographical points of interest using Python</title>
      <link>/posts/finding_geographical_points_of_interest_using_python/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/finding_geographical_points_of_interest_using_python/</guid>
      <description>This blog will take a look at scraping the TomTom and Google Places APIs to get all the points of interest in an area. A recursive grid search algorithm is discussed that efficiently identifies all of the POIs in a large area where there is a limit on the number of results the API returns. 
TomTom vs Google First, let&amp;rsquo;s compare each API:
    TomTom Google Places     Max free daily requests 2500 2500   Max results returned 100 20   Point search Yes Yes   Max point search radius none 50km   Rectangle search Yes No   Up-to-date No Yes    In each case, you need to register for your own API key which you include as a parameter in the search.</description>
    </item>
    
    <item>
      <title>Blogging from a Python Jupyter Notebook</title>
      <link>/posts/blogging_from_jupyter/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/blogging_from_jupyter/</guid>
      <description>This is a follow on post to Stefan&amp;rsquo;s original to show how to generate a blog post from a Jupyter Notebook instead of an R markdown. This post itself started off life as a Jupyter Notebook which lives in the same content/posts folder as the other Rmd files used for the site. We&amp;rsquo;ll walk through how it became a blog post.
The process is a little more complicated than for the Rmd files (since that&amp;rsquo;s what Blogdown was built for but we can still get it to work relatively easily.</description>
    </item>
    
  </channel>
</rss>