<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine_learning on </title>
    <link>/tags/machine_learning/</link>
    <description>Recent content in Machine_learning on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 13 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/machine_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Condensed R For Data Science: Data Visualisation</title>
      <link>/posts/data-visualisation/</link>
      <pubDate>Fri, 13 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/data-visualisation/</guid>
      <description>Data Visualisation Chapter Aesthetic mapping Exercises Facets Geoms Geom Exercises Statistical Transformations Transformation Exercises Position Adjustments position = identity position = fill position = dodge Something interesting: position = jitter  Position Adjustment exercises Coordinate Systems Coord_flip() Coord_quickmap() Coord_polar()  Coordinate Systems Exercises Layered Grammar of Graphics    This piece is part of a series that serves as a condensed help guide that I use to explore R and the tidyverse packages as I work through R for Data Science available here</description>
    </item>
    
    <item>
      <title>Explaining machine learning models</title>
      <link>/posts/dalex_explainers/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/dalex_explainers/</guid>
      <description>Overview The data The problem Benchmark many models with caret Set crossvalidation parameters Build model data framework Train models Visualize the residuals  Introducing DALEX explainers! Model performance Variable Importance Variable response Prediction breakdown    Packages library(tidyverse) library(caret) library(magrittr) library(DALEX)  Overview This blog will cover DALEX explainers. These are very useful when we need to validate a model or explain why a model made the prediction it made on an observation basis.</description>
    </item>
    
    <item>
      <title>Serving a machine learning model via API</title>
      <link>/posts/testing_apis_in_r/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/testing_apis_in_r/</guid>
      <description>About the Plumer package In oder to serve our API we will make use of the great Plumer package in R
 To read more about this package go to:
https://www.rplumber.io/docs/
 Setup Load in some packages.
If you are going to host the api on a suse or redhat linux server make sure you have all the dependencies as well as the packages installed to follow through this example yourself.</description>
    </item>
    
    <item>
      <title>Benchmarking machine learning models in parallel</title>
      <link>/posts/benchmarking_in_parallel/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/benchmarking_in_parallel/</guid>
      <description>Overview Having just started playing with deeplearning models in R, I wanted to visually compare them to other more traditional ML workflows. Of course, deeplearning is generally used where other models fail, but with no need for feature selection and rapidly increasing power and ease of use they may just evolve into a general learning paradigm.
 However, with tabular data and packages like caret the machine learning methods have become so streamlined that minimal user input is required at all.</description>
    </item>
    
    <item>
      <title>A Soft Introduction to Machine Learning</title>
      <link>/posts/intro-machine-learning/</link>
      <pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/intro-machine-learning/</guid>
      <description>Important machine learning libraries Future additions  Part 1 - Data Preprocessing Part 2 - Regression Simple Linear Regression Multiple linear regression Polynomial Regression Support vector machine regression Regression Trees Random forest regression A more robust application of machine learning regressions (random forest)  Part 3 - Clustering K-means  Part 4 - Dimensionality Reduction Create PCA  Part 5 - Reinforced Learning Multi-Armed Bandit Problem Upper Confidence Bound (UCB) method Improve results using UCB Visualize the model add selection  Part 6 - Parameter Grid Search, Cross-validation and Boosting Grid Search and Parameter Tuning XGBoost    Important machine learning libraries I created this document to serve as an easy introduction to basic machine learning methods.</description>
    </item>
    
  </channel>
</rss>